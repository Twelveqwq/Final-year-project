{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KD树构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kd树节点类\n",
    "class kd_node:\n",
    "    \"\"\"\n",
    "    定义kd树节点类\n",
    "    self: 节点类，用于表示树中的每个点\n",
    "    point: 节点对应的点\n",
    "    label: 点对应的标签\n",
    "    left: 左子树\n",
    "    right: 右子树\n",
    "    split_dim: 表示该节点分割数据的维度; 指示了节点分割数据的维度, 从0开始计算\n",
    "    \"\"\"\n",
    "    def __init__(self, point=None, label=None, left=None, right=None, split_dim=0, depth=0):\n",
    "        self.point = point\n",
    "        self.label = label\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.split_dim = split_dim\n",
    "        self.depth = depth\n",
    "\n",
    "#递归构造kd树，返回根节点     \n",
    "def tree(data, label, depth = 0):\n",
    "    if len(data) == 0:                                                              #检查，用于避免对空数据结构执行排序操作\n",
    "        return None\n",
    "\n",
    "    Combined = list(zip(data, label))                                               #将数据点和标签配对\n",
    "    window_size = data.shape[0]                                                     #每个维度拥有的数据集的数量\n",
    "    channel = data.shape[1]                                                         #k是数据的维度数\n",
    "    split_dim = depth % channel                                                     #split_dim通过depth和k取模，一直在0到k-1之间循环\n",
    "    \n",
    "    sorted_data = sorted(Combined, key = lambda x:x[0][split_dim])                  #按照数据点的维度进行排序，x[0]是数据点，x[1]是标签\n",
    "    medianNumber = window_size // 2                                                 #确定数据的中心点\n",
    "    medianData, medianLabel = sorted_data[medianNumber]\n",
    "\n",
    "    #建立当前节点，并递归构建左右子树\n",
    "    node = kd_node(point=medianData, label=medianLabel,depth=depth)                 #节点为数据中心点\n",
    "    left = np.array([item[0] for item in sorted_data[:medianNumber]])\n",
    "    leftLabel = np.array([item[1] for item in sorted_data[:medianNumber]])\n",
    "    right = np.array([item[0] for item in sorted_data[medianNumber+1:]])\n",
    "    rightLabel = [item[1] for item in sorted_data[medianNumber+1:]]\n",
    "    \n",
    "    node.left=tree(left, leftLabel,depth=depth+1)                #数据中心点向左包括中心点归于左子树；depth加一进行下一个分类\n",
    "    node.right=tree(right, rightLabel ,depth=depth+1)             #数据中心点向右的点归于右子树；depth加一进行下一个分类\n",
    "    #返回当前节点\n",
    "    return node                                                                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#距离计算函数，欧氏距离；当前节点到目标点的距离\n",
    "def Calculate_d(point1, point2):\n",
    "    distance = np.sqrt(np.sum((point1-point2)**2))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KD树搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建kd树类\n",
    "class kdtree:\n",
    "    def __init__(self,dataset,label):\n",
    "        self.root = tree(data=dataset, label=label)\n",
    "\n",
    "    #kd树搜索\n",
    "    def searchKDtree(self, point, k = 20):\n",
    "        \"\"\"\n",
    "        1.  从根节点出发进行查找，根据当前深度计算比较的特征维度\n",
    "            若目标节点的特征值小于当前节点的特征值，则遍历左子树，否则遍历右子树\n",
    "        2.  找到叶子节点后，将其暂时标记为当前最邻近的点\n",
    "        3.  递归地向上回退，在回退时需要：\n",
    "                如果当前节点与目标结点的距离更近，则更新最邻近节点为当前节点\n",
    "                如果当前节点对应特征与目标节点对应特征的值距离小于当前最小值时，\n",
    "                    进入当前节点的另一个子节点进行查找，有可能存在更近的节点，\n",
    "                    否则的话继续向上回退\n",
    "        4.  回退到根节点结束，得到最邻近的点\n",
    "\n",
    "        1.point: 需要进行判断的数\n",
    "        2.k    : 附近的点\n",
    "        \"\"\"\n",
    "        #检查kd树是否存在，否则不执行\n",
    "        if self is None:                              \n",
    "            return None\n",
    "        \n",
    "        #用于记录搜索路径上的节点信息，以便在需要时回溯到之前的节点\n",
    "        stack = []\n",
    "        #储存离目标点最近的几个点/标签以及距离\n",
    "        nearest_nodes = []   \n",
    "        correspond_label = []               \n",
    "        nearest_distances = []\n",
    "\n",
    "        #在kd树中搜索，并确定point会落在哪个叶子节点上\n",
    "        data_node = self.root                                               #储存根节点；kd树结构为根节点下左右子节点树，下一个循环后目标点更新成左节点或右节点，一直循环，直到目标点为none\n",
    "        data_point = data_node.point                                        #从当前节点中提取数据点\n",
    "        label = data_node.label                                             #从当前节点中提取标签\n",
    "        while data_node:                                                    #当前节点根据循环不停向下递归查找最邻近的点，直到提取数据点为None结束循环\n",
    "            stack.append(data_node)                                         #存储数据点和标签，将当前节点信息存储于堆栈中\n",
    "            distance = Calculate_d(data_point,point)                        #测量当前目标节点和测试点之间的距离\n",
    "            if len(nearest_nodes) < k:                                      #判断附近点的数量是否达到目标值\n",
    "                nearest_nodes.append(data_point)\n",
    "                correspond_label.append(label)\n",
    "                nearest_distances.append(distance)\n",
    "            else:                                       \n",
    "                max_distance = max(nearest_distances)                       #提取存储距离中的最大值                        \n",
    "                if distance < max_distance:                                 #两者做对比，如果新距离更小，用新数据替换旧数据\n",
    "                    max_index = nearest_distances.index(max_distance)\n",
    "                    nearest_distances[max_index] = distance\n",
    "                    nearest_nodes[max_index] = data_point\n",
    "                    correspond_label[max_index] = label\n",
    "            #得到当前节点的维度\n",
    "            axis = data_node.split_dim\n",
    "            if point[axis] < data_point[axis]:                              #比较当前维度下目标点和数据点的大小，判断下一个是左子树还是右子树\n",
    "                data_node = data_node.left\n",
    "            else:\n",
    "                data_node = data_node.right\n",
    "\n",
    "        #向上回溯查找是否有更近的点\n",
    "        while stack:\n",
    "            current_node = stack.pop()\n",
    "            data_point = current_node.point                                     #从当前节点中提取数据点\n",
    "            label = current_node.label                                          #从当前节点中提取标签\n",
    "            #current_distance = Calculate_d(data_point,point)                   #计算当前节点和目标点的距离\n",
    "            max_distance = max(nearest_distances)                               #提取存储距离中的最大值\n",
    "            axis = current_node.split_dim                                       #得到当前节点的维度\n",
    "            #判断邻近点是否达到需要的最近节点数，判断是否需要转到另一区域搜索\n",
    "            if len(nearest_nodes) < k or abs(point[axis] - data_point[axis]) < max_distance:\n",
    "                #搜索与之前相反的区域\n",
    "                if point[axis] < data_point[axis]:                              #比较当前维度下目标点和数据点的大小，判断下一个是左子树还是右子树\n",
    "                    current_node = current_node.right\n",
    "                else:\n",
    "                    current_node = current_node.left\n",
    "                if current_node is None:\n",
    "                    continue\n",
    "                #重复之前的搜索\n",
    "\n",
    "                data_point = current_node.point                                        #从当前节点中提取数据点\n",
    "                label = current_node.label                                             #从当前节点中提取标签\n",
    "                if current_node:                                                       #当前节点根据循环不停向下递归查找最邻近的点，直到提取数据点为None结束循环\n",
    "                    stack.append(current_node)                                         #存储数据点和标签，将当前节点信息存储于堆栈中\n",
    "                    distance = Calculate_d(data_point,point)                        #测量当前目标节点和测试点之间的距离\n",
    "                    if len(nearest_nodes) < k:                                      #判断附近点的数量是否达到目标值\n",
    "                        nearest_nodes.append(data_point)\n",
    "                        correspond_label.append(label)\n",
    "                        nearest_distances.append(distance)\n",
    "                    else:                                       \n",
    "                        max_distance = max(nearest_distances)                       #提取存储距离中的最大值                        \n",
    "                        if distance < max_distance:                                 #两者做对比，如果新距离更小，用新数据替换旧数据\n",
    "                            max_index = nearest_distances.index(max_distance)\n",
    "                            nearest_distances[max_index] = distance\n",
    "                            nearest_nodes[max_index] = data_point\n",
    "                            correspond_label[max_index] = label\n",
    "\n",
    "        return nearest_nodes, nearest_distances, correspond_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义KNN分类函数，和找到合适k值的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN分类函数\n",
    "def knn_classify(kd_tree, point, k):\n",
    "    #使用查找函数得到k个最邻近的点和对应标签\n",
    "    nearest_nodes, nearest_distances, nearest_labels = kd_tree.searchKDtree(point, k)\n",
    "    # 将标签转换为元组并计数\n",
    "    label_counts = Counter(tuple(label) for label in nearest_labels)\n",
    "\n",
    "    # 找到最常见的标签\n",
    "    most_common_label = max(label_counts, key=label_counts.get)\n",
    "    # 计算每个邻居的权重，这里使用距离的倒数作为权重\n",
    "    #nearest_distances = np.array(nearest_distances).reshape(-1)\n",
    "    #nearest_labels = np.array(nearest_labels).reshape(-1)\n",
    "    #weights = 1 / (nearest_distances + 1e-10)  # 添加一个很小的数值，避免除以零\n",
    "    # 对标签进行加权求和\n",
    "    #weighted_sum = np.dot(nearest_labels, weights)\n",
    "    # 对权重求和，得到归一化系数\n",
    "    #normalization_factor = np.sum(weights)\n",
    "    # 计算加权平均后的预测标签\n",
    "    #predicted_label = round(weighted_sum / normalization_factor)\n",
    "    predicted_label = most_common_label\n",
    "    return predicted_label\n",
    "\n",
    "def kfold(X_train, y_train):\n",
    "    # 选择不同的k值进行交叉验证\n",
    "    best_k = None\n",
    "    best_score = 0\n",
    "     \n",
    "    #使用 KFold 进行交叉验证\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for k in range(1, 100):\n",
    "        #初始化准确度总和\n",
    "        accuracy_sum = 0\n",
    "       \n",
    "       #对训练集进行交叉验证\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "            y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "           \n",
    "           #构建KD树\n",
    "            kd_tree = kdtree(X_train_fold, y_train_fold)\n",
    "           \n",
    "           #在验证集上评估模型\n",
    "            y_pred = [knn_classify(kd_tree, point, k) for point in X_val_fold]\n",
    "            accuracy = np.mean(y_pred == y_val_fold)\n",
    "            accuracy_sum += accuracy\n",
    "       \n",
    "        #计算平均准确度\n",
    "        avg_accuracy = accuracy_sum / kf.get_n_splits(X_train)\n",
    "       #更新最佳 k 值和最高准确度\n",
    "        if avg_accuracy > best_score:\n",
    "            best_score = avg_accuracy\n",
    "            best_k = k\n",
    "    return best_k, best_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到最适合的k值，并进行模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9531, 1)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "file = h5py.File('DB2_S1_feature_200_0.h5','r')\n",
    "featureData   = file['featureData'][:]\n",
    "featureLabel  = file['featureLabel'][:]\n",
    "file.close()\n",
    "\n",
    "featureData = MinMaxScaler().fit_transform(featureData) # 缩放到[0, 1]\n",
    "train_x, test_x, train_y, test_y = train_test_split(featureData, featureLabel, test_size=0.2)\n",
    "print(train_y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k, best_score = kfold(train_x, train_y)\n",
    "\n",
    "#用best_k进行一次模型评估\n",
    "#将数据和标签分训练集和测试集\n",
    "#Data_train, Data_test, Label_train, Label_test = train_test_split(data, label, test_size=0.2, random_state=42)\n",
    "\n",
    "#构建KD树\n",
    "kd_tree = kdtree(train_x, train_y)\n",
    "#对测试集进行批量预测\n",
    "Label_pred = [knn_classify(kd_tree, point, best_k) for point in test_x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.15190935795216115\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_y = np.array(test_y)\n",
    "Label_pred_array = np.array(Label_pred)\n",
    "\n",
    "\n",
    "#评估模型性能\n",
    "accuracy = accuracy_score(test_y, Label_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn库中的knn对比精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6017624842635334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=7)\n",
    "knn_model.fit(train_x, train_y)\n",
    "y_pred = knn_model.predict(test_x)\n",
    "accuracy = accuracy_score(test_y, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6722618548048678\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
